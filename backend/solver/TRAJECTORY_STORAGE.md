# Trajectory File Storage Implementation

## Overview

This implementation adds automatic downloading and storage of trajectory files generated by mini-swe-agent during solve sessions. Trajectory files contain valuable analytics data including:

- Agent execution steps and conversation history
- Model statistics (API calls, costs)
- Exit status and submission details
- Complete message history between agent and system

## Components

### 1. Data Models (`sandbox.py`)

#### `TrajectoryMetadata`
Extracted metadata from trajectory files:
- `exit_status`: Final execution status (e.g., "Submitted", "Finished")
- `submission`: Submission text or PR details
- `instance_cost`: Total cost in USD for the solve run
- `api_calls`: Number of API calls made to the model
- `mini_version`: Version of mini-swe-agent used
- `model_name`: Model identifier used for solving
- `total_messages`: Count of messages in the conversation

#### Updated `SandboxRunResult`
Added fields to track trajectory data:
- `local_trajectory_path`: Local filesystem path where trajectory is stored
- `trajectory_metadata`: Parsed metadata from the trajectory file

### 2. Storage Configuration

**Environment Variable:**
```bash
TRAJECTORY_STORAGE_DIR=/tmp/yudai/trajectories  # Default location
```

**Storage Structure:**
```
/tmp/yudai/trajectories/
├── {solve_id}_{run_id}_{timestamp}.traj.json
├── {solve_id}_{run_id}_{timestamp}.traj.json
└── ...
```

**File Naming Convention:**
```
{solve_id}_{run_id}_{YYYYMMDD_HHMMSS}.traj.json
```

Example: `a1b2c3d4_e5f6g7h8_20250112_143022.traj.json`

### 3. Sandbox Operations (`sandbox.py`)

#### `AsyncSandbox.read_file(path: str) -> bytes`
Downloads file content from E2B sandbox.

#### `parse_trajectory_metadata(trajectory_data: Dict) -> TrajectoryMetadata`
Extracts structured metadata from trajectory JSON.

#### `download_trajectory_file(...) -> Tuple[Optional[str], Optional[TrajectoryMetadata]]`
Downloads trajectory from sandbox and saves locally:
1. Reads file from sandbox using E2B SDK
2. Creates timestamped filename
3. Saves to local storage directory
4. Parses and extracts metadata
5. Returns local path and metadata

### 4. Execution Flow

#### In `HeadlessSandboxExecutor.run()`:

```python
# After agent execution completes:
1. Extract trajectory file path from stdout
2. If trajectory_file, solve_id, and run_id are present:
   a. Download file from sandbox
   b. Save to local storage
   c. Parse metadata
   d. Include in SandboxRunResult
3. Continue with normal result processing
```

### 5. Database Storage (`manager.py`)

#### Updated `_record_success()`:

Stores trajectory information in `SolveRun.trajectory_data`:

```json
{
  "remote_path": "/home/user/trajectory.json",
  "local_path": "/tmp/yudai/trajectories/a1b2c3d4_e5f6g7h8_20250112_143022.traj.json",
  "metadata": {
    "exit_status": "Submitted",
    "submission": "...",
    "instance_cost": 0.017876,
    "api_calls": 17,
    "mini_version": "1.14.4",
    "model_name": "x-ai/grok-4-fast",
    "total_messages": 42
  }
}
```

Also updates `SolveRun.diagnostics` with `local_trajectory_path`.

## Usage Example

```python
from solver.sandbox import HeadlessSandboxExecutor, HeadlessSandboxRequest

executor = HeadlessSandboxExecutor()
request = HeadlessSandboxRequest(
    issue_url="https://github.com/owner/repo/issues/123",
    repo_url="https://github.com/owner/repo",
    branch_name="main",
    model_name="anthropic/claude-sonnet-4-5-20250929",
    solve_id="a1b2c3d4",
    solve_run_id="e5f6g7h8",
    verbose=True
)

result = await executor.run(request)

if result.local_trajectory_path:
    print(f"Trajectory saved: {result.local_trajectory_path}")
    print(f"Cost: ${result.trajectory_metadata.instance_cost}")
    print(f"API Calls: {result.trajectory_metadata.api_calls}")
    print(f"Exit Status: {result.trajectory_metadata.exit_status}")
```

## Error Handling

The implementation includes robust error handling:

1. **Missing trajectory file**: Logs info, continues execution
2. **Download failure**: Logs error, returns None for paths/metadata
3. **Parse failure**: Logs warning, stores trajectory but metadata is None
4. **Missing solve_id/run_id**: Skips download (logs info)

All errors are non-fatal - the solve run continues even if trajectory download fails.

## Future Enhancements

### Phase 1 (Current)
✅ Download trajectories from sandbox
✅ Store in local temp directory
✅ Parse and store metadata
✅ Save paths in database

### Phase 2 (Planned)
- [ ] Upload to cloud storage bucket (S3/GCS)
- [ ] Implement retention policies
- [ ] Add trajectory viewer API endpoint
- [ ] Create analytics dashboard
- [ ] Trajectory comparison tools

## Testing Checklist

- [ ] Verify trajectory downloads after successful run
- [ ] Verify trajectory downloads after failed run
- [ ] Check metadata parsing with various trajectory formats
- [ ] Verify database storage of trajectory data
- [ ] Test with missing solve_id/run_id
- [ ] Test with non-existent trajectory file
- [ ] Verify temp directory creation
- [ ] Check file permissions
- [ ] Test concurrent downloads (multiple runs)
- [ ] Verify cleanup on cancellation

## Storage Considerations

### Disk Space
- Average trajectory size: 50-500 KB per run
- Estimated: ~100 MB per 1000 runs
- Implement cleanup policy after cloud upload

### Performance
- Download happens after agent execution (non-blocking)
- Async file operations minimize impact
- Parsing is lightweight (only metadata extracted)

### Security
- Files stored in system temp directory
- Access controlled by filesystem permissions
- Consider encryption for sensitive data in Phase 2

## Monitoring

**Key Metrics to Track:**
- Trajectory download success rate
- Average trajectory file size
- Download duration
- Storage directory size
- Parse failure rate
- Metadata extraction accuracy

**Log Messages:**
```
INFO: Downloading trajectory from sandbox: /home/user/trajectory.json
INFO: Trajectory saved to: /tmp/yudai/trajectories/a1b2c3d4_e5f6g7h8_20250112_143022.traj.json
INFO: Trajectory metadata: exit_status=Submitted, cost=0.017876, api_calls=17
WARNING: Failed to download trajectory file from sandbox
ERROR: Failed to parse trajectory metadata: ...
```

## Configuration

### Environment Variables

```bash
# Trajectory storage directory (default: /tmp/yudai/trajectories)
TRAJECTORY_STORAGE_DIR=/path/to/storage

# Optional: Configure in docker-compose or .env
```

### Directory Permissions

Ensure the storage directory is writable:
```bash
mkdir -p /tmp/yudai/trajectories
chmod 755 /tmp/yudai/trajectories
```

## Troubleshooting

### Problem: Trajectories not downloading
**Check:**
1. solve_id and solve_run_id are provided in request
2. Agent script generates trajectory file
3. Storage directory exists and is writable
4. E2B sandbox can read files

### Problem: Parse failures
**Check:**
1. Trajectory file is valid JSON
2. Expected fields exist in trajectory structure
3. File encoding is UTF-8

### Problem: Disk space issues
**Solution:**
1. Implement cleanup cron job
2. Move to cloud storage sooner
3. Compress old trajectories

## API Integration

The trajectory data is accessible via the solve status endpoint:

```bash
GET /api/sessions/{session_id}/solves/{solve_id}/status
```

Response includes:
```json
{
  "runs": [
    {
      "id": "e5f6g7h8",
      "trajectory_data": {
        "local_path": "/tmp/yudai/trajectories/...",
        "metadata": { ... }
      }
    }
  ]
}
```

## Conclusion

This implementation provides a robust foundation for trajectory file management. The current phase focuses on reliable capture and storage, with future phases planned for cloud integration and advanced analytics.


